{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9987c011-4cfe-466f-a52a-d98be0478be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>trip_creation_time</th>\n",
       "      <th>route_schedule_uuid</th>\n",
       "      <th>route_type</th>\n",
       "      <th>trip_uuid</th>\n",
       "      <th>source_center</th>\n",
       "      <th>source_name</th>\n",
       "      <th>destination_center</th>\n",
       "      <th>destination_name</th>\n",
       "      <th>od_start_time</th>\n",
       "      <th>...</th>\n",
       "      <th>cutoff_timestamp</th>\n",
       "      <th>actual_distance_to_destination</th>\n",
       "      <th>actual_time</th>\n",
       "      <th>osrm_time</th>\n",
       "      <th>osrm_distance</th>\n",
       "      <th>factor</th>\n",
       "      <th>segment_actual_time</th>\n",
       "      <th>segment_osrm_time</th>\n",
       "      <th>segment_osrm_distance</th>\n",
       "      <th>segment_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training</td>\n",
       "      <td>2018-09-20 02:35:36.476840</td>\n",
       "      <td>thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...</td>\n",
       "      <td>Carting</td>\n",
       "      <td>trip-153741093647649320</td>\n",
       "      <td>IND388121AAA</td>\n",
       "      <td>Anand_VUNagar_DC (Gujarat)</td>\n",
       "      <td>IND388620AAB</td>\n",
       "      <td>Khambhat_MotvdDPP_D (Gujarat)</td>\n",
       "      <td>2018-09-20 03:21:32.418600</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-09-20 04:27:55</td>\n",
       "      <td>10.435660</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.9653</td>\n",
       "      <td>1.272727</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.9653</td>\n",
       "      <td>1.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training</td>\n",
       "      <td>2018-09-20 02:35:36.476840</td>\n",
       "      <td>thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...</td>\n",
       "      <td>Carting</td>\n",
       "      <td>trip-153741093647649320</td>\n",
       "      <td>IND388121AAA</td>\n",
       "      <td>Anand_VUNagar_DC (Gujarat)</td>\n",
       "      <td>IND388620AAB</td>\n",
       "      <td>Khambhat_MotvdDPP_D (Gujarat)</td>\n",
       "      <td>2018-09-20 03:21:32.418600</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-09-20 04:17:55</td>\n",
       "      <td>18.936842</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.7243</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.7590</td>\n",
       "      <td>1.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training</td>\n",
       "      <td>2018-09-20 02:35:36.476840</td>\n",
       "      <td>thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...</td>\n",
       "      <td>Carting</td>\n",
       "      <td>trip-153741093647649320</td>\n",
       "      <td>IND388121AAA</td>\n",
       "      <td>Anand_VUNagar_DC (Gujarat)</td>\n",
       "      <td>IND388620AAB</td>\n",
       "      <td>Khambhat_MotvdDPP_D (Gujarat)</td>\n",
       "      <td>2018-09-20 03:21:32.418600</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-09-20 04:01:19.505586</td>\n",
       "      <td>27.637279</td>\n",
       "      <td>40.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>32.5395</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.8152</td>\n",
       "      <td>2.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>training</td>\n",
       "      <td>2018-09-20 02:35:36.476840</td>\n",
       "      <td>thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...</td>\n",
       "      <td>Carting</td>\n",
       "      <td>trip-153741093647649320</td>\n",
       "      <td>IND388121AAA</td>\n",
       "      <td>Anand_VUNagar_DC (Gujarat)</td>\n",
       "      <td>IND388620AAB</td>\n",
       "      <td>Khambhat_MotvdDPP_D (Gujarat)</td>\n",
       "      <td>2018-09-20 03:21:32.418600</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-09-20 03:39:57</td>\n",
       "      <td>36.118028</td>\n",
       "      <td>62.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>45.5620</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0224</td>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>training</td>\n",
       "      <td>2018-09-20 02:35:36.476840</td>\n",
       "      <td>thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...</td>\n",
       "      <td>Carting</td>\n",
       "      <td>trip-153741093647649320</td>\n",
       "      <td>IND388121AAA</td>\n",
       "      <td>Anand_VUNagar_DC (Gujarat)</td>\n",
       "      <td>IND388620AAB</td>\n",
       "      <td>Khambhat_MotvdDPP_D (Gujarat)</td>\n",
       "      <td>2018-09-20 03:21:32.418600</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-09-20 03:33:55</td>\n",
       "      <td>39.386040</td>\n",
       "      <td>68.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>54.2181</td>\n",
       "      <td>1.545455</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.9153</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144862</th>\n",
       "      <td>training</td>\n",
       "      <td>2018-09-20 16:24:28.436231</td>\n",
       "      <td>thanos::sroute:f0569d2f-4e20-4c31-8542-67b86d5...</td>\n",
       "      <td>Carting</td>\n",
       "      <td>trip-153746066843555182</td>\n",
       "      <td>IND131028AAB</td>\n",
       "      <td>Sonipat_Kundli_H (Haryana)</td>\n",
       "      <td>IND000000ACB</td>\n",
       "      <td>Gurgaon_Bilaspur_HB (Haryana)</td>\n",
       "      <td>2018-09-20 16:24:28.436231</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-09-20 21:57:20</td>\n",
       "      <td>45.258278</td>\n",
       "      <td>94.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>67.9280</td>\n",
       "      <td>1.566667</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.1858</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144863</th>\n",
       "      <td>training</td>\n",
       "      <td>2018-09-20 16:24:28.436231</td>\n",
       "      <td>thanos::sroute:f0569d2f-4e20-4c31-8542-67b86d5...</td>\n",
       "      <td>Carting</td>\n",
       "      <td>trip-153746066843555182</td>\n",
       "      <td>IND131028AAB</td>\n",
       "      <td>Sonipat_Kundli_H (Haryana)</td>\n",
       "      <td>IND000000ACB</td>\n",
       "      <td>Gurgaon_Bilaspur_HB (Haryana)</td>\n",
       "      <td>2018-09-20 16:24:28.436231</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-09-20 21:31:18</td>\n",
       "      <td>54.092531</td>\n",
       "      <td>120.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>85.6829</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>26.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>17.3725</td>\n",
       "      <td>1.238095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144864</th>\n",
       "      <td>training</td>\n",
       "      <td>2018-09-20 16:24:28.436231</td>\n",
       "      <td>thanos::sroute:f0569d2f-4e20-4c31-8542-67b86d5...</td>\n",
       "      <td>Carting</td>\n",
       "      <td>trip-153746066843555182</td>\n",
       "      <td>IND131028AAB</td>\n",
       "      <td>Sonipat_Kundli_H (Haryana)</td>\n",
       "      <td>IND000000ACB</td>\n",
       "      <td>Gurgaon_Bilaspur_HB (Haryana)</td>\n",
       "      <td>2018-09-20 16:24:28.436231</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-09-20 21:11:18</td>\n",
       "      <td>66.163591</td>\n",
       "      <td>140.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>97.0933</td>\n",
       "      <td>1.590909</td>\n",
       "      <td>20.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>20.7053</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144865</th>\n",
       "      <td>training</td>\n",
       "      <td>2018-09-20 16:24:28.436231</td>\n",
       "      <td>thanos::sroute:f0569d2f-4e20-4c31-8542-67b86d5...</td>\n",
       "      <td>Carting</td>\n",
       "      <td>trip-153746066843555182</td>\n",
       "      <td>IND131028AAB</td>\n",
       "      <td>Sonipat_Kundli_H (Haryana)</td>\n",
       "      <td>IND000000ACB</td>\n",
       "      <td>Gurgaon_Bilaspur_HB (Haryana)</td>\n",
       "      <td>2018-09-20 16:24:28.436231</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-09-20 20:53:19</td>\n",
       "      <td>73.680667</td>\n",
       "      <td>158.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>111.2709</td>\n",
       "      <td>1.612245</td>\n",
       "      <td>17.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>18.8885</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144866</th>\n",
       "      <td>training</td>\n",
       "      <td>2018-09-20 16:24:28.436231</td>\n",
       "      <td>thanos::sroute:f0569d2f-4e20-4c31-8542-67b86d5...</td>\n",
       "      <td>Carting</td>\n",
       "      <td>trip-153746066843555182</td>\n",
       "      <td>IND131028AAB</td>\n",
       "      <td>Sonipat_Kundli_H (Haryana)</td>\n",
       "      <td>IND000000ACB</td>\n",
       "      <td>Gurgaon_Bilaspur_HB (Haryana)</td>\n",
       "      <td>2018-09-20 16:24:28.436231</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-09-20 16:24:28.436231</td>\n",
       "      <td>70.039010</td>\n",
       "      <td>426.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>88.7319</td>\n",
       "      <td>4.484211</td>\n",
       "      <td>268.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.8088</td>\n",
       "      <td>29.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144867 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            data          trip_creation_time  \\\n",
       "0       training  2018-09-20 02:35:36.476840   \n",
       "1       training  2018-09-20 02:35:36.476840   \n",
       "2       training  2018-09-20 02:35:36.476840   \n",
       "3       training  2018-09-20 02:35:36.476840   \n",
       "4       training  2018-09-20 02:35:36.476840   \n",
       "...          ...                         ...   \n",
       "144862  training  2018-09-20 16:24:28.436231   \n",
       "144863  training  2018-09-20 16:24:28.436231   \n",
       "144864  training  2018-09-20 16:24:28.436231   \n",
       "144865  training  2018-09-20 16:24:28.436231   \n",
       "144866  training  2018-09-20 16:24:28.436231   \n",
       "\n",
       "                                      route_schedule_uuid route_type  \\\n",
       "0       thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...    Carting   \n",
       "1       thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...    Carting   \n",
       "2       thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...    Carting   \n",
       "3       thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...    Carting   \n",
       "4       thanos::sroute:eb7bfc78-b351-4c0e-a951-fa3d5c3...    Carting   \n",
       "...                                                   ...        ...   \n",
       "144862  thanos::sroute:f0569d2f-4e20-4c31-8542-67b86d5...    Carting   \n",
       "144863  thanos::sroute:f0569d2f-4e20-4c31-8542-67b86d5...    Carting   \n",
       "144864  thanos::sroute:f0569d2f-4e20-4c31-8542-67b86d5...    Carting   \n",
       "144865  thanos::sroute:f0569d2f-4e20-4c31-8542-67b86d5...    Carting   \n",
       "144866  thanos::sroute:f0569d2f-4e20-4c31-8542-67b86d5...    Carting   \n",
       "\n",
       "                      trip_uuid source_center                 source_name  \\\n",
       "0       trip-153741093647649320  IND388121AAA  Anand_VUNagar_DC (Gujarat)   \n",
       "1       trip-153741093647649320  IND388121AAA  Anand_VUNagar_DC (Gujarat)   \n",
       "2       trip-153741093647649320  IND388121AAA  Anand_VUNagar_DC (Gujarat)   \n",
       "3       trip-153741093647649320  IND388121AAA  Anand_VUNagar_DC (Gujarat)   \n",
       "4       trip-153741093647649320  IND388121AAA  Anand_VUNagar_DC (Gujarat)   \n",
       "...                         ...           ...                         ...   \n",
       "144862  trip-153746066843555182  IND131028AAB  Sonipat_Kundli_H (Haryana)   \n",
       "144863  trip-153746066843555182  IND131028AAB  Sonipat_Kundli_H (Haryana)   \n",
       "144864  trip-153746066843555182  IND131028AAB  Sonipat_Kundli_H (Haryana)   \n",
       "144865  trip-153746066843555182  IND131028AAB  Sonipat_Kundli_H (Haryana)   \n",
       "144866  trip-153746066843555182  IND131028AAB  Sonipat_Kundli_H (Haryana)   \n",
       "\n",
       "       destination_center               destination_name  \\\n",
       "0            IND388620AAB  Khambhat_MotvdDPP_D (Gujarat)   \n",
       "1            IND388620AAB  Khambhat_MotvdDPP_D (Gujarat)   \n",
       "2            IND388620AAB  Khambhat_MotvdDPP_D (Gujarat)   \n",
       "3            IND388620AAB  Khambhat_MotvdDPP_D (Gujarat)   \n",
       "4            IND388620AAB  Khambhat_MotvdDPP_D (Gujarat)   \n",
       "...                   ...                            ...   \n",
       "144862       IND000000ACB  Gurgaon_Bilaspur_HB (Haryana)   \n",
       "144863       IND000000ACB  Gurgaon_Bilaspur_HB (Haryana)   \n",
       "144864       IND000000ACB  Gurgaon_Bilaspur_HB (Haryana)   \n",
       "144865       IND000000ACB  Gurgaon_Bilaspur_HB (Haryana)   \n",
       "144866       IND000000ACB  Gurgaon_Bilaspur_HB (Haryana)   \n",
       "\n",
       "                     od_start_time  ...            cutoff_timestamp  \\\n",
       "0       2018-09-20 03:21:32.418600  ...         2018-09-20 04:27:55   \n",
       "1       2018-09-20 03:21:32.418600  ...         2018-09-20 04:17:55   \n",
       "2       2018-09-20 03:21:32.418600  ...  2018-09-20 04:01:19.505586   \n",
       "3       2018-09-20 03:21:32.418600  ...         2018-09-20 03:39:57   \n",
       "4       2018-09-20 03:21:32.418600  ...         2018-09-20 03:33:55   \n",
       "...                            ...  ...                         ...   \n",
       "144862  2018-09-20 16:24:28.436231  ...         2018-09-20 21:57:20   \n",
       "144863  2018-09-20 16:24:28.436231  ...         2018-09-20 21:31:18   \n",
       "144864  2018-09-20 16:24:28.436231  ...         2018-09-20 21:11:18   \n",
       "144865  2018-09-20 16:24:28.436231  ...         2018-09-20 20:53:19   \n",
       "144866  2018-09-20 16:24:28.436231  ...  2018-09-20 16:24:28.436231   \n",
       "\n",
       "        actual_distance_to_destination  actual_time  osrm_time osrm_distance  \\\n",
       "0                            10.435660         14.0       11.0       11.9653   \n",
       "1                            18.936842         24.0       20.0       21.7243   \n",
       "2                            27.637279         40.0       28.0       32.5395   \n",
       "3                            36.118028         62.0       40.0       45.5620   \n",
       "4                            39.386040         68.0       44.0       54.2181   \n",
       "...                                ...          ...        ...           ...   \n",
       "144862                       45.258278         94.0       60.0       67.9280   \n",
       "144863                       54.092531        120.0       76.0       85.6829   \n",
       "144864                       66.163591        140.0       88.0       97.0933   \n",
       "144865                       73.680667        158.0       98.0      111.2709   \n",
       "144866                       70.039010        426.0       95.0       88.7319   \n",
       "\n",
       "          factor  segment_actual_time  segment_osrm_time  \\\n",
       "0       1.272727                 14.0               11.0   \n",
       "1       1.200000                 10.0                9.0   \n",
       "2       1.428571                 16.0                7.0   \n",
       "3       1.550000                 21.0               12.0   \n",
       "4       1.545455                  6.0                5.0   \n",
       "...          ...                  ...                ...   \n",
       "144862  1.566667                 12.0               12.0   \n",
       "144863  1.578947                 26.0               21.0   \n",
       "144864  1.590909                 20.0               34.0   \n",
       "144865  1.612245                 17.0               27.0   \n",
       "144866  4.484211                268.0                9.0   \n",
       "\n",
       "        segment_osrm_distance  segment_factor  \n",
       "0                     11.9653        1.272727  \n",
       "1                      9.7590        1.111111  \n",
       "2                     10.8152        2.285714  \n",
       "3                     13.0224        1.750000  \n",
       "4                      3.9153        1.200000  \n",
       "...                       ...             ...  \n",
       "144862                 8.1858        1.000000  \n",
       "144863                17.3725        1.238095  \n",
       "144864                20.7053        0.588235  \n",
       "144865                18.8885        0.629630  \n",
       "144866                 8.8088       29.777778  \n",
       "\n",
       "[144867 rows x 24 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ddf = pd.read_csv(\"./Data/delhivery_data.csv\")\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502c701c-5360-489f-b48a-fa5054e32407",
   "metadata": {},
   "source": [
    "# Cleaning,Deleting and sorting columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7418b65-4d42-43e5-b3b3-51eb52374d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_scan_to_end_scan</th>\n",
       "      <th>actual_distance_to_destination</th>\n",
       "      <th>actual_time</th>\n",
       "      <th>osrm_time</th>\n",
       "      <th>osrm_distance</th>\n",
       "      <th>segment_actual_time</th>\n",
       "      <th>segment_osrm_time</th>\n",
       "      <th>segment_osrm_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>144867.000000</td>\n",
       "      <td>144867.000000</td>\n",
       "      <td>144867.000000</td>\n",
       "      <td>144867.000000</td>\n",
       "      <td>144867.000000</td>\n",
       "      <td>144867.000000</td>\n",
       "      <td>144867.000000</td>\n",
       "      <td>144867.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>961.262986</td>\n",
       "      <td>234.073372</td>\n",
       "      <td>416.927527</td>\n",
       "      <td>213.868272</td>\n",
       "      <td>284.771297</td>\n",
       "      <td>36.196111</td>\n",
       "      <td>18.507548</td>\n",
       "      <td>22.82902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1037.012769</td>\n",
       "      <td>344.990009</td>\n",
       "      <td>598.103621</td>\n",
       "      <td>308.011085</td>\n",
       "      <td>421.119294</td>\n",
       "      <td>53.571158</td>\n",
       "      <td>14.775960</td>\n",
       "      <td>17.86066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>9.000045</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.008200</td>\n",
       "      <td>-244.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>161.000000</td>\n",
       "      <td>23.355874</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>29.914700</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>12.07010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>449.000000</td>\n",
       "      <td>66.126571</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>78.525800</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>23.51300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1634.000000</td>\n",
       "      <td>286.708875</td>\n",
       "      <td>513.000000</td>\n",
       "      <td>257.000000</td>\n",
       "      <td>343.193250</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>27.81325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7898.000000</td>\n",
       "      <td>1927.447705</td>\n",
       "      <td>4532.000000</td>\n",
       "      <td>1686.000000</td>\n",
       "      <td>2326.199100</td>\n",
       "      <td>3051.000000</td>\n",
       "      <td>1611.000000</td>\n",
       "      <td>2191.40370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       start_scan_to_end_scan  actual_distance_to_destination    actual_time  \\\n",
       "count           144867.000000                   144867.000000  144867.000000   \n",
       "mean               961.262986                      234.073372     416.927527   \n",
       "std               1037.012769                      344.990009     598.103621   \n",
       "min                 20.000000                        9.000045       9.000000   \n",
       "25%                161.000000                       23.355874      51.000000   \n",
       "50%                449.000000                       66.126571     132.000000   \n",
       "75%               1634.000000                      286.708875     513.000000   \n",
       "max               7898.000000                     1927.447705    4532.000000   \n",
       "\n",
       "           osrm_time  osrm_distance  segment_actual_time  segment_osrm_time  \\\n",
       "count  144867.000000  144867.000000        144867.000000      144867.000000   \n",
       "mean      213.868272     284.771297            36.196111          18.507548   \n",
       "std       308.011085     421.119294            53.571158          14.775960   \n",
       "min         6.000000       9.008200          -244.000000           0.000000   \n",
       "25%        27.000000      29.914700            20.000000          11.000000   \n",
       "50%        64.000000      78.525800            29.000000          17.000000   \n",
       "75%       257.000000     343.193250            40.000000          22.000000   \n",
       "max      1686.000000    2326.199100          3051.000000        1611.000000   \n",
       "\n",
       "       segment_osrm_distance  \n",
       "count           144867.00000  \n",
       "mean                22.82902  \n",
       "std                 17.86066  \n",
       "min                  0.00000  \n",
       "25%                 12.07010  \n",
       "50%                 23.51300  \n",
       "75%                 27.81325  \n",
       "max               2191.40370  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.drop(['route_schedule_uuid','cutoff_factor','factor','segment_factor', 'cutoff_timestamp', 'is_cutoff', 'route_type', 'trip_uuid','trip_creation_time','source_center','destination_center'],axis=1, inplace= True)\n",
    "ddf[\"Sstate\"] = ddf[\"source_name\"].str.extract(r\"\\((.*?)\\)\")\n",
    "ddf[\"Dstate\"] = ddf[\"destination_name\"].str.extract(r\"\\((.*?)\\)\") #maybe needed\n",
    "#ddf = ddf.dropna(thresh = 1)\n",
    "#ddf['segment_actual_time'] = ddf['segment_actual_time'].clip(lower=0) #keeping it to make the RMSE low\n",
    "ddf['source_name'] = ddf['source_name'].fillna(ddf['source_name'].mode()[0])\n",
    "ddf['destination_name'] = ddf['destination_name'].fillna(ddf['destination_name'].mode()[0])\n",
    "ddf['Sstate'] = ddf['Sstate'].fillna(ddf['Sstate'].mode()[0])\n",
    "ddf['Dstate'] = ddf['Dstate'].fillna(ddf['Dstate'].mode()[0])\n",
    "ddf.isnull().sum()\n",
    "ddf.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca5d24b-b5a4-4698-9f8e-80e93f64d384",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Extracting Unique source and destination names, and then extracting city, area, state into 4 500row files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3247a2d4-d8ff-4417-804e-aec1f244a31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1643\n",
      "place    0\n",
      "dtype: int64\n",
      "Processed 1643 rows and saved into 4 CSV files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(0, len(unique_values), 500):\\n    chunk = unique_values[i:i+500]\\n    # Create a DataFrame with the chunk under the column name 'place_name'\\n    pd.DataFrame({'place_name': chunk}).to_csv(\\n        f'loc{counter}.csv', \\n        index=False\\n    )\\n    counter += 1\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_unique = pd.concat([ddf['source_name'], ddf['destination_name']]).nunique(dropna=True)\n",
    "print(num_unique)\n",
    "import pandas as pd\n",
    "\n",
    "unique_values = pd.concat([ddf['source_name'], ddf['destination_name']]).dropna().unique()\n",
    "unique_values = pd.DataFrame(unique_values, columns=['place'])\n",
    "unique_values.to_csv(\"DELH_unique_values.csv\",index= False)\n",
    "print(unique_values.isnull().sum())\n",
    "import pandas as pd\n",
    "\n",
    "# Define the parsing function\n",
    "def parse_place(s):\n",
    "    s = s.strip()  # Remove leading/trailing whitespace\n",
    "    original = s\n",
    "    # Extract state from parentheses\n",
    "    if '(' in s and ')' in s:\n",
    "        start = s.find('(') + 1\n",
    "        end = s.find(')')\n",
    "        if start < end:\n",
    "            state = s[start:end].strip()\n",
    "            main_part = s[:start-1].strip()\n",
    "        else:\n",
    "            state = ''\n",
    "            main_part = s\n",
    "    else:\n",
    "        state = ''\n",
    "        main_part = s\n",
    "    \n",
    "    # Process the main part\n",
    "    if '_' in main_part:\n",
    "        parts = main_part.split('_')\n",
    "        if len(parts) ==4:\n",
    "            city = parts[0].strip()\n",
    "            area = parts[1].strip()\n",
    "            abbreviation = parts[2].strip() + parts[3].strip()\n",
    "        elif len(parts) == 3:\n",
    "            city = parts[0].strip()\n",
    "            area = parts[1].strip()\n",
    "            abbreviation = parts[2].strip()\n",
    "        elif len(parts) == 2:\n",
    "            city = parts[0].strip()\n",
    "            area = ''\n",
    "            abbreviation = parts[1].strip()\n",
    "        elif len(parts) == 1:\n",
    "            city = parts[0].strip()\n",
    "            area = ''\n",
    "            abbreviation = ''\n",
    "        else:\n",
    "            # Rare case with more than 3 parts; set all to empty\n",
    "            city = ''\n",
    "            area = ''\n",
    "            abbreviation = ''\n",
    "    else:\n",
    "        parts = main_part.split()\n",
    "        if len(parts) > 1:\n",
    "            last_part = parts[-1]\n",
    "            if last_part.lower() == state.lower() and state:\n",
    "                # Last part matches state, treat main_part as area\n",
    "                area = main_part\n",
    "                city = ''\n",
    "                abbreviation = ''\n",
    "            elif len(last_part) <= 3:\n",
    "                # Last part is short, treat as abbreviation\n",
    "                abbreviation = last_part\n",
    "                if len(parts) == 2:\n",
    "                    city = parts[0]\n",
    "                    area = ''\n",
    "                elif len(parts) == 3:\n",
    "                    city = parts[0]\n",
    "                    area = parts[1]\n",
    "                else:\n",
    "                    # More than 3 parts; first as city, middle as area\n",
    "                    city = parts[0]\n",
    "                    area = ' '.join(parts[1:-1])\n",
    "                    abbreviation = last_part\n",
    "            else:\n",
    "                # Last part not short, treat main_part as city\n",
    "                city = main_part\n",
    "                area = ''\n",
    "                abbreviation = ''\n",
    "        else:\n",
    "            # Single part\n",
    "            city = main_part\n",
    "            area = ''\n",
    "            abbreviation = ''\n",
    "    \n",
    "    return original,city, area, abbreviation, state\n",
    "# Parse the 'place' column\n",
    "parsed_data = [parse_place(place) for place in unique_values['place']]\n",
    "\n",
    "# Create a new dataframe with parsed components\n",
    "df = pd.DataFrame(parsed_data, columns=['original','city', 'area', 'abbreviation', 'state'])\n",
    "\n",
    "# Split into chunks of 500 rows and save to CSV files\n",
    "chunk_size = 500\n",
    "num_chunks = (len(df) + chunk_size - 1) // chunk_size  # Ceiling division\n",
    "for i in range(num_chunks):\n",
    "    chunk = df.iloc[i * chunk_size : (i + 1) * chunk_size]\n",
    "    chunk.to_csv(f'./Data/locations_part{i+1}.csv', index=False)\n",
    "\n",
    "print(f\"Processed {len(df)} rows and saved into {num_chunks} CSV files.\")\n",
    "'''\n",
    "for i in range(0, len(unique_values), 500):\n",
    "    chunk = unique_values[i:i+500]\n",
    "    # Create a DataFrame with the chunk under the column name 'place_name'\n",
    "    pd.DataFrame({'place_name': chunk}).to_csv(\n",
    "        f'loc{counter}.csv', \n",
    "        index=False\n",
    "    )\n",
    "    counter += 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433125ea-3feb-4bc4-9e9b-4bd393a07bcb",
   "metadata": {},
   "source": [
    "# Preparing Geocoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd6f7fdd-9d52-4e2e-8dfc-62d38af8a7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_original               0\n",
      "original_city                   3\n",
      "original_area                 191\n",
      "original_abbreviation          41\n",
      "original_state                  0\n",
      "lat                             0\n",
      "lon                             0\n",
      "formatted                       0\n",
      "name                         1344\n",
      "housenumber                  1598\n",
      "street                       1378\n",
      "suburb                       1480\n",
      "district                     1558\n",
      "postcode                      580\n",
      "city                          136\n",
      "county_code                  1176\n",
      "county                        158\n",
      "state                           5\n",
      "state_code                     11\n",
      "country                         0\n",
      "country_code                    0\n",
      "confidence_building_level    1642\n",
      "confidence                      1\n",
      "confidence_street_level      1518\n",
      "confidence_city_level         425\n",
      "attribution                     1\n",
      "attribution_license             1\n",
      "attribution_url                 1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Combining the geocoded data into a file\n",
    "import pandas as pd\n",
    "\n",
    "# List of CSV file names\n",
    "files = [\"lc1.csv\", \"lc2.csv\", \"lc3.csv\", \"lc4.csv\"]\n",
    "er = pd.read_csv(\"ef1.csv\")\n",
    "# Read and combine all CSV files into one DataFrame \n",
    "dataframes = [pd.read_csv(file) for file in files]\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "combined_df.dropna(subset=['lon','lat'],inplace=True)\n",
    "combined_df = pd.concat([combined_df, er], ignore_index=True)\n",
    "print(combined_df.isnull().sum())\n",
    "combined_df = pd.DataFrame(combined_df)\n",
    "\n",
    "'''\n",
    "filtered_df = combined_df[combined_df[['lon', 'lat']].isna().sum(axis=1) >= 2]\n",
    "filtered_df.to_csv(\"empty_rows.csv\", index=False)\n",
    "'''\n",
    "combined_df.drop(['attribution','state','attribution_license','confidence','state_code','attribution_url','original_area','original_abbreviation','confidence_city_level','confidence_street_level','confidence_building_level','country_code','country','state','county_code','district','suburb','street','housenumber','name'], axis=1,inplace=True)\n",
    "combined_df = combined_df.rename(columns={'original_original': 'original','formatted':'loc_formatted'})\n",
    "# Write the combined DataFrame to a new CSV file\n",
    "'''\n",
    "filtered_df = combined_df[combined_df[['lon', 'lat']].isna().sum(axis=1) >= 2]\n",
    "filtered_df.to_csv(\"empty_rows.csv\", index=False)\n",
    "'''\n",
    "\n",
    "# Merge source_name with geocoded data\n",
    "ddf = ddf.merge(\n",
    "    combined_df, left_on=\"source_name\", right_on=\"original\", how=\"left\"\n",
    ").rename(columns={\"lat\": \"source_lat\", \"lon\": \"source_long\"}).drop(columns=[\"original\"])\n",
    "\n",
    "# Merge destination_name with geocoded data\n",
    "ddf = ddf.merge(\n",
    "    combined_df, left_on=\"destination_name\", right_on=\"original\", how=\"left\"\n",
    ").rename(columns={\"lat\": \"destination_lat\", \"lon\": \"destination_long\"}).drop(columns=[\"original\"])\n",
    "\n",
    "ddf.drop(['original_state_x','original_state_y'], axis=1, inplace=True)\n",
    "\n",
    "ddf = ddf[[\"data\", \"source_name\", \"destination_name\", \"od_start_time\", \"od_end_time\",\"start_scan_to_end_scan\",\"actual_distance_to_destination\",\"actual_time\",\"osrm_time\",\"osrm_distance\",\"segment_actual_time\",\"segment_osrm_time\",\"segment_osrm_distance\",\"source_lat\",\"source_long\",\"destination_lat\",\"destination_long\",\"postcode_x\",\"postcode_y\",\"city_x\",\"city_y\",\"county_x\",\"county_y\",\"Sstate\",'Dstate',\"loc_formatted_x\",\"loc_formatted_y\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cd3588a-af43-49ab-b98e-c128cea86167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate Haversine distance\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great-circle distance between two points \n",
    "    on Earth (specified in decimal degrees) using the Haversine formula.\n",
    "    \n",
    "    Parameters:\n",
    "    lat1, lon1: Latitude and Longitude of point 1 (in decimal degrees)\n",
    "    lat2, lon2: Latitude and Longitude of point 2 (in decimal degrees)\n",
    "    \n",
    "    Returns:\n",
    "    Distance in kilometers\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    \n",
    "    # Haversine formula\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    \n",
    "    # Radius of Earth in kilometers (approximately 6371 km)\n",
    "    R = 6371\n",
    "    distance = R * c\n",
    "    \n",
    "    return distance\n",
    "\n",
    "\n",
    "# Add Haversine distance column\n",
    "ddf['haversine_distance'] = ddf.apply(\n",
    "    lambda row: haversine_distance(\n",
    "        row['source_lat'], \n",
    "        row['source_long'], \n",
    "        row['destination_lat'], \n",
    "        row['destination_long']\n",
    "    ), \n",
    "    axis=1\n",
    ")\n",
    "ddf_cleaned = ddf.drop_duplicates(subset=['source_name', 'destination_name'], keep='first')\n",
    "ddf_cleaned.to_csv(\"nR.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebb99738-a35b-4249-a3a1-76117b13bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.to_csv(\"delh.csv\",index = False)\n",
    "ddf['data'] = ddf['data'].str.strip()\n",
    "dx = ddf[ddf['data'] == 'training']\n",
    "dt = ddf[ddf['data'] == 'test']\n",
    "dx.drop(['data'],axis=1)\n",
    "dt.drop(['data'],axis=1)\n",
    "#dt = ddf[dff['data'] == 'testing']]\n",
    "dt.to_csv(\"test.csv\", index = False)\n",
    "dx.to_csv(\"train.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
